---
layout: post
title: R et big data
comments: true

---

R et les bases de données de grandes dimensions ne font pas souvent bon ménage, du moins la version de base de R. Si vous essayez de lire une base de données de 1Go avec R, il est très fort probable que la machine se plante. La rapidité d'execution de R depends, bien sûr, de la capacité de votre machine et de la version de R. De nouveaux open source  ont vu le jour et ont mis l'accent sur la rapidité d'execution comparativement à R. C'est surtout le cas de [**Julia**](http://julialang.org/) et de certains modules statistiques de [**python**](https://www.python.org/) (pandas, Numpy). Mais comme R regorge des developpeurs de talent, des packages assez interessants ont vu le jour recemment: on s'interessera dans ce billet à **data.table** et à **dplyr**.
Remarquons qu'il existait d'autres packages comme **ff** (et bien d'autres comme **bigmemory**,**filehash**,**ffbase**,etc) pour traiter des données volumineuses. 
Dans ce billet, nous allons nous à une base du recensement d'un pays avec près de 6 millions d'individus et 35 variables.




### Big data sans utilisation de packages

Pour importer une base dans R sans avoir recours aux packages, la fonction **read.csv()** avec deux options importantes permet de s'en sortir:

1. preciser le nombre de colonne ( **nrow**) permet à R de savoir l'espace de memoire a alloué à l'importation de la base;

2. demander à R de ne pas changer les variables qualitatives en facteur à partir de la fonction **stringAsFactor=FALSE**


{% highlight r %}
base<-read.csv("POPULATION.csv",nrow=6.1e6,stringsAsFactors=FALSE,sep=";")
{% endhighlight %}
Et vous pouvez travailler sur votre base. Pour la rapidité, ça dependra de la puissance de votre machine. A partir de quelques millions d'individus, cette fonction est inopérante.

Pour travailler sans soucis, vaut mieux utiliser des packages.


### Utilisation des packages

Recemment, j'ai utilisé deux packages très interessants pour la lecture et la manipulation des données: **data.table** et **dplyr**.
Dans cet exemple, **data.table** nous permettra de lire  et de manipuler les données et **dplyr** pour sa simplicité dans la manipulation des données.

1. package **data.table**

Le package **data.table** est un package developpé par Matthew Dowle, un ancien de Lheman Brothers. C'est un package qui permet d'importer des données assez volumineuses avec la fonction **fread** et leur manipulation comme tout autre _data.frames_. L'importation des bases volumineuses avec ce package est très rapide (par exemple 20Go, soit à peu près 200 millions d'individus, en 8mn alors qu'avec R ou d'autres logiciels, ça prendrait des heures)

{% highlight r %}
setwd("/home/komlan/census")
library(data.table)
{% endhighlight %}



{% highlight text %}
## data.table 1.9.4  For help type: ?data.table
## *** NB: by=.EACHI is now explicit. See README to restore previous behaviour.
{% endhighlight %}



{% highlight r %}
data<-fread("POPULATION.csv",stringsAsFactors=TRUE)
{% endhighlight %}



{% highlight text %}
## 
Read 0.0% of 5847453 rows
Read 4.3% of 5847453 rows
Read 10.4% of 5847453 rows
Read 18.0% of 5847453 rows
Read 25.7% of 5847453 rows
Read 33.3% of 5847453 rows
Read 41.2% of 5847453 rows
Read 48.9% of 5847453 rows
Read 57.3% of 5847453 rows
Read 62.8% of 5847453 rows
Read 66.9% of 5847453 rows
Read 71.1% of 5847453 rows
Read 75.9% of 5847453 rows
Read 79.4% of 5847453 rows
Read 84.1% of 5847453 rows
Read 91.2% of 5847453 rows
Read 95.8% of 5847453 rows
Read 5847453 rows and 35 (of 35) columns from 0.484 GB file in 00:00:56
{% endhighlight %}

Cette base, qui contient 5847453 lignes a été lue en 56 secondes (11 seconde avec windows, 4Go de processeur). J'ai utilisé une machine virtuelle (Oracle VM) avec moins de 2Go de processeur. Même SAS ne ferait pas mieux. On peut faire des manipulations avec data.table. Se reférer à la documentation pour la prise en main.





{% highlight r %}
data[,.N,by=factor(P04)]#Effectif par sexe
{% endhighlight %}



{% highlight text %}
##    factor       N
## 1:      1 2839319
## 2:      2 3008134
{% endhighlight %}



{% highlight r %}
data[,.(moyenne=mean(P06AGE),ecart.type=sd(P06AGE))]#calcul de l'âge moyen et l'ecart-type
{% endhighlight %}



{% highlight text %}
##     moyenne ecart.type
## 1: 23.04353   19.12718
{% endhighlight %}



{% highlight r %}
data[,.(AGE.SEXE=mean(P06AGE)),by=factor(P04)]# l'âge moyen par sexe
{% endhighlight %}



{% highlight text %}
##    factor AGE.SEXE
## 1:      1 22.08893
## 2:      2 23.94456
{% endhighlight %}

2. package **dplyr**

Ce package est la version modernisée du package **plyr** du même auteur, le neo-zelandais Hadley Wickham, statisticien senior à rstudio, un des developpeurs de packages de R le plus actif de sa génération qui vient d'intégrer d'ailleurs l'équipe de developpeur de R (r core team 2014). Il est l'auteur de plusieurs packages dont **ggplot2** qui est trés utilisé dans les représentations grahiques.
Ce package est plutôt indiqué dans la manipulation des données, surtout de grande taille. Après l'importation de la base, on utilise la fonction **tbl_df** pour créer un data.frame local, ce qui permet une utilisation aisée des données. Ce package comme d'autres packages sortis ces derniers temps par rstudio, utilise la notation **%>%** qui est inspiré de **magrittr**.

Utilisons la base créée avec data.table pour la rapidité de l'importation des données

{% highlight r %}
library(dplyr)
base<-tbl_df(data)
#glimpse(base)
base%>%group_by(factor(P04))%>%summarise(moyenne=mean(P06AGE),ecart_type=sd(P06AGE),effectif=n())#moyenne, ecart-type,effectif par sexe
{% endhighlight %}



{% highlight text %}
## Source: local data frame [2 x 4]
## 
##   factor(P04)  moyenne ecart_type effectif
## 1           1 22.08893   18.57327  2839319
## 2           2 23.94456   19.59305  3008134
{% endhighlight %}



{% highlight r %}
base%>%group_by(factor(M1),factor(P04))%>%summarise(moyenne=mean(P06AGE))#age moyen par sexe et par r?gion
{% endhighlight %}



{% highlight text %}
## Source: local data frame [12 x 3]
## Groups: factor(M1)
## 
##    factor(M1) factor(P04)  moyenne
## 1           0           1 24.78628
## 2           0           2 25.11369
## 3           1           1 22.76869
## 4           1           2 25.09033
## 5           2           1 21.73734
## 6           2           2 23.01469
## 7           3           1 21.64327
## 8           3           2 23.39489
## 9           4           1 21.41060
## 10          4           2 24.51925
## 11          5           1 19.62414
## 12          5           2 21.74398
{% endhighlight %}




Ce package dispose des fonctions assez interessantes pour la manipulation des données comme **filter**, **select**, **arrange** ou **mutate**, et des fonctions pour la fusion des bases des données.

### Conclusion

Ces deux packages permettent de manipuler des données volumineuses sans trop d'efforts. Ils sont les plus utilisés de nos jours. Il y a d'autres packages assez utilisés comme **sqldf** qui utilise **SQL** pour la manipulation des bases. D'autre projets existent pour la manipulation des big data comme R et Hadoop.
Il ne s'agit ici qu'une petite introduction à la manipulation des données volumineuses. Toute personne interessée peut trouver la documentation en ligne.

R est le meilleur!!!!
